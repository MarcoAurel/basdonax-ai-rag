# Gu√≠a de Uso de APIs en la Nube

C√≥mo usar modelos de IA en la nube en lugar de modelos locales para obtener respuestas MUCHO m√°s r√°pidas.

## üåü ¬øPor Qu√© Usar APIs en la Nube?

### Ventajas
- ‚ö° **Ultra r√°pido**: 500+ tokens/segundo vs 5-15 tokens/segundo local
- üíª **Sin GPU necesaria**: No consume recursos locales
- üéØ **Mejor calidad**: Modelos m√°s grandes y potentes
- üîÑ **Sin instalaci√≥n**: No necesitas descargar modelos gigantes

### Desventajas
- üí∞ Algunos requieren pago (pero hay opciones GRATIS)
- üåê Requiere conexi√≥n a internet
- üîí Tus datos se env√≠an a servicios externos

---

## üöÄ Opci√≥n 1: Groq (RECOMENDADO - GRATIS)

### ¬øPor Qu√© Groq?
- ‚úÖ **100% GRATIS** (con l√≠mites generosos)
- ‚úÖ **Ultra r√°pido** (500+ tokens/segundo)
- ‚úÖ **Modelos potentes**: Llama 3.1, Mixtral, Gemma 2
- ‚úÖ **F√°cil de configurar**

### L√≠mites Gratuitos
- 30 solicitudes/minuto
- 6,000 tokens/minuto
- **M√°s que suficiente** para desarrollo y uso personal

### Paso a Paso

#### 1. Obtener API Key

1. Ve a: https://console.groq.com/
2. Haz clic en "Sign Up" o "Get Started"
3. Reg√≠strate con Google/GitHub/Email
4. Una vez dentro, ve a "API Keys" en el men√∫ lateral
5. Haz clic en "Create API Key"
6. Copia tu API key (empieza con `gsk_...`)

#### 2. Configurar .env

Edita el archivo `.env` en la ra√≠z del proyecto:

```env
# Groq API (GRATIS)
USE_CLOUD_API=true
CLOUD_PROVIDER=groq
GROQ_API_KEY=gsk_tu_api_key_aqui_reemplaza_esto

# Modelo a usar (opciones abajo)
MODEL_NAME=llama-3.1-70b-versatile

# Resto de configuraci√≥n
EMBEDDINGS_MODEL_NAME=all-MiniLM-L6-v2
TARGET_SOURCE_CHUNKS=5
CHROMA_HOST=chroma
CHROMA_PORT=8000
```

**Reemplaza `gsk_tu_api_key_aqui_reemplaza_esto` con tu API key real**

#### 3. Modelos Disponibles en Groq

Cambia `MODEL_NAME` seg√∫n tu preferencia:

| Modelo | Par√°metros | Velocidad | Calidad | Recomendado |
|--------|-----------|-----------|---------|-------------|
| `llama-3.1-70b-versatile` | 70B | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ **Mejor balance** |
| `llama-3.1-8b-instant` | 8B | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ **M√°s r√°pido** |
| `mixtral-8x7b-32768` | 47B | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ **Contexto largo** |
| `gemma2-9b-it` | 9B | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | **Alternativa r√°pida** |

#### 4. Rebuild y Reiniciar

```bash
# Rebuild para instalar las nuevas dependencias
.\start-local.ps1 -Build

# Espera 2-3 minutos mientras se construye
```

#### 5. Probar

1. Ve a `http://localhost:8080`
2. Haz una pregunta
3. **Deber√≠as ver una respuesta en 1-3 segundos** üöÄ

---

## üí¨ Opci√≥n 2: OpenAI (GPT-3.5 / GPT-4)

### Costos
- GPT-3.5 Turbo: ~$0.002 por 1K tokens
- GPT-4 Turbo: ~$0.03 por 1K tokens
- Aproximadamente $0.01-0.10 por consulta t√≠pica

### Paso a Paso

#### 1. Obtener API Key

1. Ve a: https://platform.openai.com/
2. Reg√≠strate/Inicia sesi√≥n
3. Ve a "API Keys"
4. Crea una nueva API key
5. C√≥piala (empieza con `sk-...`)

#### 2. Configurar .env

```env
USE_CLOUD_API=true
CLOUD_PROVIDER=openai
OPENAI_API_KEY=sk-tu_api_key_aqui

# Modelos disponibles
MODEL_NAME=gpt-3.5-turbo  # M√°s barato
# MODEL_NAME=gpt-4-turbo   # Mejor calidad, m√°s caro
# MODEL_NAME=gpt-4o        # M√°s nuevo y r√°pido

EMBEDDINGS_MODEL_NAME=all-MiniLM-L6-v2
TARGET_SOURCE_CHUNKS=5
CHROMA_HOST=chroma
CHROMA_PORT=8000
```

#### 3. Rebuild y Probar

```bash
.\start-local.ps1 -Build
```

---

## ü§ñ Opci√≥n 3: Anthropic (Claude)

### Costos
- Claude 3 Haiku: ~$0.0025 por 1K tokens (muy barato)
- Claude 3.5 Sonnet: ~$0.003 por 1K tokens
- Claude 3 Opus: ~$0.015 por 1K tokens

### Paso a Paso

#### 1. Obtener API Key

1. Ve a: https://console.anthropic.com/
2. Reg√≠strate
3. Ve a "API Keys"
4. Crea una API key
5. C√≥piala (empieza con `sk-ant-...`)

#### 2. Configurar .env

```env
USE_CLOUD_API=true
CLOUD_PROVIDER=anthropic
ANTHROPIC_API_KEY=sk-ant-tu_api_key_aqui

# Modelos disponibles
MODEL_NAME=claude-3-5-sonnet-20241022  # Mejor balance
# MODEL_NAME=claude-3-haiku-20240307   # M√°s barato
# MODEL_NAME=claude-3-opus-20240229    # Mejor calidad

EMBEDDINGS_MODEL_NAME=all-MiniLM-L6-v2
TARGET_SOURCE_CHUNKS=5
CHROMA_HOST=chroma
CHROMA_PORT=8000
```

#### 3. Rebuild y Probar

```bash
.\start-local.ps1 -Build
```

---

## üîç Opci√≥n 4: Google Gemini (GRATIS/Pago)

### Tier Gratuito
- 60 solicitudes/minuto
- Gratis hasta cierto l√≠mite

### Paso a Paso

#### 1. Obtener API Key

1. Ve a: https://makersuite.google.com/app/apikey
2. Inicia sesi√≥n con cuenta Google
3. Crea un proyecto
4. Genera una API key
5. C√≥piala

#### 2. Configurar .env

```env
USE_CLOUD_API=true
CLOUD_PROVIDER=google
GOOGLE_API_KEY=tu_api_key_aqui

# Modelos disponibles
MODEL_NAME=gemini-1.5-flash  # R√°pido, gratis
# MODEL_NAME=gemini-1.5-pro  # Mejor calidad

EMBEDDINGS_MODEL_NAME=all-MiniLM-L6-v2
TARGET_SOURCE_CHUNKS=5
CHROMA_HOST=chroma
CHROMA_PORT=8000
```

#### 3. Rebuild y Probar

```bash
.\start-local.ps1 -Build
```

---

## üîÑ Cambiar Entre Local y Cloud

### Para Usar API en la Nube

Edita `.env`:
```env
USE_CLOUD_API=true
```

### Para Volver a Local (Ollama)

Edita `.env`:
```env
USE_CLOUD_API=false
```

Luego reinicia:
```bash
docker restart basdonax-ui-local
```

**No necesitas rebuild** para cambiar entre local/cloud, solo reiniciar.

---

## üìä Comparaci√≥n de Velocidad

Tiempo promedio de respuesta para una consulta t√≠pica:

| Proveedor | Modelo | Tiempo | Costo |
|-----------|--------|--------|-------|
| **Local CPU** | phi3 | ~10-15 seg | GRATIS |
| **Local CPU** | llama3.2:1b | ~3-5 seg | GRATIS |
| **Groq** | llama-3.1-70b | **~1-2 seg** | **GRATIS** ‚≠ê |
| **Groq** | llama-3.1-8b | **~0.5-1 seg** | **GRATIS** ‚≠ê |
| **OpenAI** | gpt-3.5-turbo | ~2-3 seg | $0.01-0.05 |
| **OpenAI** | gpt-4-turbo | ~3-5 seg | $0.10-0.30 |
| **Anthropic** | claude-3-haiku | ~2-3 seg | $0.01-0.03 |
| **Anthropic** | claude-3.5-sonnet | ~2-4 seg | $0.05-0.15 |
| **Google** | gemini-1.5-flash | ~2-3 seg | GRATIS/Pago |

---

## üí° Mi Recomendaci√≥n

### Para Desarrollo y Pruebas
```env
USE_CLOUD_API=true
CLOUD_PROVIDER=groq
GROQ_API_KEY=tu_api_key
MODEL_NAME=llama-3.1-70b-versatile
```

**Por qu√©:**
- ‚úÖ GRATIS
- ‚úÖ Ultra r√°pido (1-2 segundos)
- ‚úÖ Excelente calidad
- ‚úÖ Sin l√≠mites estrictos

### Para Producci√≥n con Presupuesto
```env
USE_CLOUD_API=true
CLOUD_PROVIDER=openai
OPENAI_API_KEY=tu_api_key
MODEL_NAME=gpt-3.5-turbo
```

**Por qu√©:**
- ‚ö° Muy r√°pido
- üí∞ Barato (~$0.01-0.05 por consulta)
- üèÜ Muy buena calidad
- üìà Escalable

### Para M√°xima Calidad
```env
USE_CLOUD_API=true
CLOUD_PROVIDER=anthropic
ANTHROPIC_API_KEY=tu_api_key
MODEL_NAME=claude-3-5-sonnet-20241022
```

**Por qu√©:**
- üèÜ Mejor calidad en respuestas complejas
- üìö Excelente para an√°lisis de documentos
- üéØ Muy preciso

---

## üîí Seguridad

### Proteger tu API Key

1. **NUNCA** subas el archivo `.env` a GitHub
   - Ya est√° en `.gitignore`

2. **Rotar** tus API keys peri√≥dicamente

3. **Monitorear** el uso en los dashboards:
   - Groq: https://console.groq.com/
   - OpenAI: https://platform.openai.com/usage
   - Anthropic: https://console.anthropic.com/

4. **Configurar l√≠mites** de gasto en los dashboards

---

## üß™ Probar Ahora (Groq - GRATIS)

```bash
# 1. Obt√©n tu API key de https://console.groq.com/

# 2. Edita .env y agrega:
#    USE_CLOUD_API=true
#    CLOUD_PROVIDER=groq
#    GROQ_API_KEY=tu_api_key_aqui
#    MODEL_NAME=llama-3.1-70b-versatile

# 3. Rebuild
.\start-local.ps1 -Build

# 4. Espera 2-3 minutos

# 5. Prueba en http://localhost:8080
```

**Deber√≠as ver respuestas en ~1-2 segundos** üöÄ

---

## ‚ùì Soluci√≥n de Problemas

### Error: "API key no est√° configurada"

**Soluci√≥n:** Verifica que agregaste la API key correcta en `.env`:
```env
GROQ_API_KEY=gsk_tu_key_aqui  # Sin comillas
```

### Error: "Rate limit exceeded"

**Causa:** Excediste el l√≠mite de solicitudes

**Soluci√≥n:**
- Groq: Espera 1 minuto
- OpenAI: Revisa tu plan
- Agrega delays entre consultas

### Error: "Invalid API key"

**Soluci√≥n:**
1. Verifica que copiaste la key completa
2. Genera una nueva key
3. Verifica que no tenga espacios extras

### Las respuestas siguen lentas

**Causa:** Puede que no se haya cargado el .env

**Soluci√≥n:**
```bash
# Det√©n todo
.\start-local.ps1 -Stop

# Rebuild
.\start-local.ps1 -Build

# Verifica logs
docker logs basdonax-ui-local -f
```

---

## üìù Resumen

1. **Groq es GRATIS** y super r√°pido ‚Üí **√ösalo para desarrollo**
2. **OpenAI GPT-3.5** es barato y bueno ‚Üí **√ösalo para producci√≥n**
3. **Claude 3.5** es el mejor para an√°lisis complejos ‚Üí **√ösalo para casos especiales**
4. **NO necesitas** GPU ni modelos locales con APIs en la nube
5. **Respuestas en 1-3 segundos** vs 10-15 segundos local

---

**¬øListo para probarlo?** Empieza con Groq (gratis): https://console.groq.com/
